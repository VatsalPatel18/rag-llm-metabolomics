{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "file_path = 'combined_data.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "mean_scores = data.groupby('Model').mean().reset_index()\n",
    "mean_scores.to_csv('mean_scores_model_wise.csv', index=False)\n",
    "\n",
    "print(mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from the mean_scores DataFrame\n",
    "data = {\n",
    "    'Model': ['GPT-4 only (no RAG)', 'MedCPT w GPT-4', 'OpenAI based RAG'],\n",
    "    'faithfulness': [0.025, 0.800, 0.625],\n",
    "    'answer_correctness': [0.247741, 0.393940, 0.335267],\n",
    "    'context_recall': [0.00, 0.60, 0.55],\n",
    "    'context_precision': [0.00, 0.75, 0.80],\n",
    "    'answer_relevancy': [0.804695, 0.778907, 0.703376],\n",
    "    'ROUGE-1': [0.160930, 0.371680, 0.270215],\n",
    "    'ROUGE-2': [0.049090, 0.226840, 0.200945],\n",
    "    'ROUGE-L': [0.160930, 0.365430, 0.270215],\n",
    "    'BLEU': [0.009360, 0.015430, 0.037955]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "mean_scores = pd.DataFrame(data)\n",
    "\n",
    "# Set 'Model' as the index\n",
    "mean_scores.set_index('Model', inplace=True)\n",
    "\n",
    "# Plot using a different color palette\n",
    "colors = plt.cm.Accent.colors  # Use the 'tab10' palette\n",
    "# colors = plt.cm.Paired.colors\n",
    "mean_scores.T.plot(kind='bar', figsize=(12, 6), width=0.8, color=colors)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Mean Scores by Metric and Model', fontsize=14)\n",
    "plt.xlabel('Metrics', fontsize=12)\n",
    "plt.ylabel('Mean Scores', fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.legend(title='Model', fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = 'mean_scores_by_metric_and_model_with_tab10_palette.png'\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load the data\n",
    "file_path = 'combined_data.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for specific models\n",
    "filtered_data = data[data['Model'].isin(['OpenAI based RAG', 'MedCPT w GPT-4'])]\n",
    "\n",
    "# Identify metric columns (exclude 'Model')\n",
    "metric_columns = [col for col in filtered_data.columns if col != 'Model']\n",
    "\n",
    "# Step 2: Initialize results storage\n",
    "ks_test_results = []\n",
    "\n",
    "# Step 3: Perform K-S test for each metric\n",
    "for metric in metric_columns:\n",
    "    # Get data for the two models\n",
    "    group1 = filtered_data[filtered_data['Model'] == 'OpenAI based RAG'][metric].dropna()\n",
    "    group2 = filtered_data[filtered_data['Model'] == 'MedCPT w GPT-4'][metric].dropna()\n",
    "    \n",
    "    # Perform Kolmogorov-Smirnov test\n",
    "    if len(group1) > 1 and len(group2) > 1:  # Ensure both groups have sufficient data\n",
    "        ks_stat, ks_p = ks_2samp(group1, group2)\n",
    "    else:\n",
    "        ks_stat, ks_p = (np.nan, np.nan)\n",
    "    \n",
    "    # Store results\n",
    "    ks_test_results.append({\n",
    "        'Metric': metric,\n",
    "        'K-S Statistic': ks_stat,\n",
    "        'P-Value': ks_p\n",
    "    })\n",
    "\n",
    "# Step 4: Save results to a DataFrame and CSV\n",
    "ks_results_df = pd.DataFrame(ks_test_results)\n",
    "ks_results_df.to_csv('ks_test_results.csv', index=False)\n",
    "print(ks_results_df)\n",
    "\n",
    "# Step 5: Visualization (ECDF for Distribution Comparison)\n",
    "for metric in metric_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.ecdfplot(filtered_data[filtered_data['Model'] == 'OpenAI based RAG'][metric].dropna(), \n",
    "                 color='blue', label='OpenAI based RAG')\n",
    "    sns.ecdfplot(filtered_data[filtered_data['Model'] == 'MedCPT w GPT-4'][metric].dropna(), \n",
    "                 color='orange', label='MedCPT w GPT-4')\n",
    "    plt.title(f'ECDF of {metric}')\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel('ECDF')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load the data\n",
    "file_path = 'combined_data.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for specific models\n",
    "filtered_data = data[data['Model'].isin(['OpenAI based RAG', 'MedCPT w GPT-4'])]\n",
    "\n",
    "# Identify metric columns (exclude 'Model')\n",
    "metric_columns = [col for col in filtered_data.columns if col != 'Model']\n",
    "\n",
    "# Step 2: Initialize results storage\n",
    "shapiro_results = []\n",
    "\n",
    "# Step 3: Perform Shapiro-Wilk test for normality for each metric\n",
    "for metric in metric_columns:\n",
    "    # Get data for the two models\n",
    "    group1 = filtered_data[filtered_data['Model'] == 'OpenAI based RAG'][metric].dropna()\n",
    "    group2 = filtered_data[filtered_data['Model'] == 'MedCPT w GPT-4'][metric].dropna()\n",
    "    \n",
    "    # Perform Shapiro-Wilk test if sample size is sufficient\n",
    "    shapiro_g1_stat, shapiro_g1_p = shapiro(group1) if len(group1) >= 3 else (np.nan, np.nan)\n",
    "    shapiro_g2_stat, shapiro_g2_p = shapiro(group2) if len(group2) >= 3 else (np.nan, np.nan)\n",
    "    \n",
    "    # Store results\n",
    "    shapiro_results.append({\n",
    "        'Metric': metric,\n",
    "        'Model': 'OpenAI based RAG',\n",
    "        'Shapiro-Wilk Statistic': shapiro_g1_stat,\n",
    "        'P-Value': shapiro_g1_p\n",
    "    })\n",
    "    shapiro_results.append({\n",
    "        'Metric': metric,\n",
    "        'Model': 'MedCPT w GPT-4',\n",
    "        'Shapiro-Wilk Statistic': shapiro_g2_stat,\n",
    "        'P-Value': shapiro_g2_p\n",
    "    })\n",
    "\n",
    "# Step 4: Save results to a DataFrame and CSV\n",
    "shapiro_df = pd.DataFrame(shapiro_results)\n",
    "shapiro_df.to_csv('shapiro_wilk_results.csv', index=False)\n",
    "print(shapiro_df)\n",
    "\n",
    "# Step 5: Visualization (Histograms for Normality Check)\n",
    "for metric in metric_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(filtered_data[filtered_data['Model'] == 'OpenAI based RAG'][metric].dropna(), \n",
    "                 kde=True, color='blue', label='OpenAI based RAG', bins=20)\n",
    "    sns.histplot(filtered_data[filtered_data['Model'] == 'MedCPT w GPT-4'][metric].dropna(), \n",
    "                 kde=True, color='orange', label='MedCPT w GPT-4', bins=20)\n",
    "    plt.title(f'Histogram of {metric}')\n",
    "    plt.xlabel(metric)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, kruskal, ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# Filter for specific models\n",
    "filtered_data = data[data['Model'].isin(['OpenAI based RAG', 'MedCPT w GPT-4'])]\n",
    "\n",
    "# Define your metrics\n",
    "metrics = ['faithfulness', 'answer_relevancy', 'BLEU']\n",
    "\n",
    "# Mann-Whitney U Test for non-parametric comparison between two groups\n",
    "for metric in metrics:\n",
    "    group1 = filtered_data[filtered_data['Model'] == 'OpenAI based RAG'][metric].dropna()\n",
    "    group2 = filtered_data[filtered_data['Model'] == 'MedCPT w GPT-4'][metric].dropna()\n",
    "    stat, p = mannwhitneyu(group1, group2)\n",
    "    print(f'Mann-Whitney U Test for {metric}: Statistic={stat}, p-value={p}')\n",
    "\n",
    "# Welch's ANOVA for metrics with unequal variances\n",
    "for metric in metrics:\n",
    "    model = ols(f'{metric} ~ Model', data=filtered_data).fit()\n",
    "    welch_anova = sm.stats.anova_lm(model, typ=2, robust='hc3')\n",
    "    print(f'Welch\\'s ANOVA for {metric}:\\n', welch_anova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
